import streamlit as st
import torch
import re
from transformers import MT5ForConditionalGeneration, AutoTokenizer

# Model yolu ve cihaz ayarÄ±
model_path = "./mt5_summary_model"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Model ve tokenizer yÃ¼kle (AutoTokenizer ile uyumluluk saÄŸlanÄ±r)
model = MT5ForConditionalGeneration.from_pretrained(model_path).to(device)
model.eval()
tokenizer = AutoTokenizer.from_pretrained(model_path, legacy=False)

# Temizleme fonksiyonlarÄ±
def clean_input(text):
    text = re.sub(r'\s+', ' ', text.replace('\n', ' ').replace('\t', ' ').replace('\\', ' '))
    return text.strip()

def clean_output(text):
    text = re.sub(r'<extra_id_\d+>, ', '', text).strip()
    text = re.sub(r'<extra_id_\d+>', '', text).strip()
    return text

# Ã–zetleme fonksiyonu
def summarize(text):
    input_text = "Ã–zetle: " + clean_input(text)
    inputs = tokenizer(
        input_text,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=1024
    ).to(device)

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_length=256,
            min_length=50,
            num_beams=6,                
            repetition_penalty=2.0,     
            no_repeat_ngram_size=4,     
            length_penalty=1.0,
            early_stopping=True,
            do_sample=False        
        )

    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)
    print(f"Ã–zet: {summary}")
    return clean_output(summary)

def summarize_sampling(text):
    input_text = "Ã–zetle: " + clean_input(text)
    inputs = tokenizer(
        input_text,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=1024
    ).to(device)

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_length=256,
            do_sample=True,              # sampling aktif
            top_k=30,
            top_p=0.92,
            repetition_penalty=2.0,       # ğŸ”¼ Daha yÃ¼ksek ceza, daha az kopya
            no_repeat_ngram_size=4,       # ğŸ”¼ 4 kelimelik tekrarlarÄ± engelle
            length_penalty=1.0,           # ğŸ” CÃ¼mle uzunluÄŸunu cezalandÄ±rmaz
            early_stopping=True,
            num_return_sequences=1,       # Tek Ã¼retim (Ã§oklu Ã¼retimle kalite seÃ§imi yapÄ±labilir)
        )

    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)
    print(f"Ã–zet: {summary}")
    return clean_output(summary)

# Streamlit arayÃ¼zÃ¼
st.title("ğŸ“„ TÃ¼rkÃ§e Haber Ã–zetleyici")
st.write("EÄŸittiÄŸiniz Ã¶zel mT5 modeliyle haberleri otomatik olarak Ã¶zetleyin.")

user_input = st.text_area("ğŸ“° Haberi buraya yapÄ±ÅŸtÄ±rÄ±n:", height=300)

if st.button("ğŸ“Œ Ã–zetle"):
    if user_input.strip():
        with st.spinner("Model Ã§alÄ±ÅŸÄ±yor..."):
            print(user_input)
            summary = summarize(user_input)
        st.success("âœ… Ã–zet:")
        st.write(summary)
    else:
        st.warning("LÃ¼tfen bir metin girin.")

if st.button("ğŸ“Œ DoÄŸal Ã–zetle"):
    if user_input.strip():
        with st.spinner("Model Ã§alÄ±ÅŸÄ±yor..."):
            print(user_input)
            summary = summarize_sampling(user_input)
        st.success("âœ… Ã–zet:")
        st.write(summary)
    else:
        st.warning("LÃ¼tfen bir metin girin.")
